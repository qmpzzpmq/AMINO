variables:
  audioset_path: "/audioset"
  batch_size: 256
  dataloaders_num_workers: 0

# it is necessary in module
pipeline_size:
  num_classes: ???

defaults:
  - override hydra/job_logging: AMINO_default
  - override hydra/output: AMINO_default

datamodule:
  datasets:
    train:
      - select: "AMINO.datamodule.datasets:AUDIOSET_DATASET"
        conf:
          data_dir: ${variables.audioset_path}
          dataset: "balanced_train"
    val:
      - select: "AMINO.datamodule.datasets:AUDIOSET_DATASET"
        conf:
          data_dir: ${variables.audioset_path}
          dataset: "eval"
    test: 
      -  null
  after_transform:
    train:
      - select: "AMINO.datamodule.preprocess:LogMelSpectrogram"
        conf:
          n_fft: ${pipeline_size.nfft}
          n_mels: ${pipeline_size.num_mels}
      - select: "AMINO.datamodule.preprocess:Feature_Unfold"
        conf:
          n_frame: ${pipeline_size.feature_unfold}
      - select: "AMINO.datamodule.preprocess:SpecAug"
        conf:
          frequency_mask:
            F: 30
            num_mask: 2
          time_mask:
            T: 30
            num_mask: 2
          time_streatch:
            floor: 0.9
            ceil: 1.1
    val:
      - select: "AMINO.datamodule.preprocess:LogMelSpectrogram"
        conf:
          n_fft: ${pipeline_size.nfft}
          n_mels: ${pipeline_size.num_mels}
      - select: "AMINO.datamodule.preprocess:Feature_Unfold"
        conf:
          n_frame: ${pipeline_size.feature_unfold}
    test:
      - select: "AMINO.datamodule.preprocess:LogMelSpectrogram"
        conf:
          n_fft: ${pipeline_size.nfft}
          n_mels: ${pipeline_size.num_mels}
      - select: "AMINO.datamodule.preprocess:Feature_Unfold"
        conf:
          n_frame: ${pipeline_size.feature_unfold}
  dataloaders:
    train:
      batch_size: ${variables.batch_size}
      num_workers: ${variables.dataloaders_num_workers}
    val:
      batch_size: ${variables.batch_size}
      num_workers: ${variables.dataloaders_num_workers}
  collect_fns:
    train:
      pad_choices: ['pad', 'onehot']
    val:
      pad_choices: ['pad', 'onehot']
    test:
      pad_choices: ['pad', 'onehot']

module:
  select: "AMINO.modules.classifier:AMINO_CLASSIFIER"
  conf:
    net:
      select: "AMINO.modules.nets.classifier:AMINO_CLASSIFIER"
      conf:
        encoder:
          select: "AMINO.modules.nets.encoder:AMINO_TRANSFORMER_ENCODER"
          conf:
            feature_dim: "${product: ${pipeline_size.num_mels}, ${pipeline_size.feature_unfold}}"
            num_block: 12
            num_layers_reuse: 1
            dim_feedforward: 2048
            d_model: 256
            nhead: 8
        decoders:
          classifier:
            select: "AMINO.modules.nets.classifier:AMINO_GP_DECODER"
            conf:
              buncher:
                select: "AMINO.modules.nets.buncher:SIMPLE_LINEAR_BUNCHER"
                conf:
                  num_hidden: ${module.conf.net.conf.encoder.conf.d_model}
                  num_classes: ${pipeline_size.num_classes}
              pooler:
                select: "AMINO.modules.nets.pooler:SIMPLE_POOLER"
                conf:
                  pooling_method: "mean"
    losses:
      net:
        classifier:
          select: "AMINO.modules.label_smoothing_loss:LABEL_SMOOTHING_LOSS"
          conf:
            size: ${pipeline_size.num_classes}
            smoothing: 0.0
      weight:
        classifier: 1.0

trainer:
  gpus:
    - 0
    - 1
  auto_scale_batch_size: null
  log_every_n_steps: 1
  strategy: "ddp"

callbacks:
- select: pytorch_lightning.callbacks.progress.tqdm_progress:TQDMProgressBar
  conf:
    refresh_rate: 1
    process_position: 0
- select: pytorch_lightning.callbacks.model_checkpoint:ModelCheckpoint
  conf:
    filename: epoch{epoch}-val_loss_total_epoch{val_loss_total_epoch:.3f}
    monitor: val_loss_total_epoch
    save_last: true
    save_top_k: 5
    dirpath: checkpoint
- select: pytorch_lightning.callbacks.early_stopping:EarlyStopping
  conf:
    monitor: val_loss_total_epoch
    mode: min
    min_delta: 1.0e-06
    patience: 30
- select: pytorch_lightning.callbacks:DeviceStatsMonitor
  conf: {}
- select: pytorch_lightning.callbacks.lr_monitor:LearningRateMonitor
  conf:
    logging_interval: epoch
- select: pytorch_lightning.callbacks:ModelSummary
  conf:
    max_depth: 3