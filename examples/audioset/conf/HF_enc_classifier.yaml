variables:
  audioset_path: "/audioset_Kong/"
  batch_size: 1
  dataloaders_num_workers: 0
  token_nj: "flexible"
  # token_nj: 20

# it is necessary in module
pipeline_size:
  num_classes: ???

defaults:
  - override hydra/job_logging: AMINO_default
  - override hydra/output: AMINO_default

datamodule:
  datasets:
    train:
      - select: "AMINO.datamodule.datasets:AUDIOSET_DATASET"
        conf:
          data_dir: ${variables.audioset_path}
          # dataset: "balanced_train"
          dataset: "unbalanced_train"
          json_path: "data/unbalanced_train.scp"
          token_nj: ${variables.token_nj}
    val:
      - select: "AMINO.datamodule.datasets:AUDIOSET_DATASET"
        conf:
          data_dir: ${variables.audioset_path}
          dataset: "eval"
          json_path: "data/eval.scp"
    test: 
      -  null
  after_transform:
    train: null
    val: null
    test: null
  dataloaders:
    train:
      batch_size: ${variables.batch_size}
      num_workers: ${variables.dataloaders_num_workers}
    val:
      batch_size: ${variables.batch_size}
      num_workers: ${variables.dataloaders_num_workers}
      shuffle: False
  collect_fns:
    train:
      pad_choices: ['pad', 'onehot']
    val:
      pad_choices: ['pad', 'onehot']
    test:
      pad_choices: ['pad', 'onehot']

module:
  select: "AMINO.modules.classifier:AMINO_CLASSIFIER"
  conf:
    net:
      select: "AMINO.modules.nets.classifier:AMINO_CLASSIFIER"
      conf:
        encoder:
          select: "AMINO.modules.nets.encoder:HUGGINGFACE_WAV2VEC2"
          conf:
            config: null
            from_pretrained: "facebook/wav2vec2-base-960h"
            from_pretrained_num_hidden_layers: 3
        decoders:
          classifier:
            select: "AMINO.modules.nets.classifier:AMINO_GP_DECODER"
            conf:
              buncher:
                select: "AMINO.modules.nets.buncher:SIMPLE_LINEAR_BUNCHER"
                conf:
                  num_hidden: 768
                  num_classes: ${pipeline_size.num_classes}
              pooler:
                select: "AMINO.modules.nets.pooler:SIMPLE_POOLER"
                conf:
                  pooling_method: "mean"
    scheduler:
      select: "AMINO.modules.scheduler:WarmupLR"
      conf:
        warmup_steps: 2000
    losses:
      net:
        classifier:
          select: "AMINO.modules.label_smoothing_loss:LABEL_SMOOTHING_LOSS"
          conf:
            size: ${pipeline_size.num_classes}
            smoothing: 0.0
      weight:
        classifier: 1.0

trainer:
  gpus:
    - 0
    - 1
  auto_scale_batch_size: null
  log_every_n_steps: 1
  strategy: "ddp"
  limit_train_batches: 5

callbacks:
- select: pytorch_lightning.callbacks.progress.tqdm_progress:TQDMProgressBar
  conf:
    refresh_rate: 1
    process_position: 0
# - select: pytorch_lightning.callbacks.model_checkpoint:ModelCheckpoint
#   conf:
#     filename: epoch{epoch}-val_loss_total_epoch{val_loss_total_epoch:.3f}
#     monitor: val_loss_total_epoch
#     save_last: true
#     save_top_k: 5
#     dirpath: checkpoint
# - select: pytorch_lightning.callbacks.early_stopping:EarlyStopping
#   conf:
#     monitor: val_loss_total_epoch
#     mode: min
#     min_delta: 1.0e-06
#     patience: 30
- select: pytorch_lightning.callbacks:DeviceStatsMonitor
  conf: {}
- select: pytorch_lightning.callbacks.lr_monitor:LearningRateMonitor
  conf:
    logging_interval: epoch
- select: pytorch_lightning.callbacks:ModelSummary
  conf:
    max_depth: 3